import {useRef, useState, useCallback, useEffect} from 'react';

// --- ê¸°ë³¸ ì„¤ì •ê°’ (í•„ìš”ì‹œ ì¡°ì • ê°€ëŠ¥) ---
const RMS_THRESHOLD = 0.015; // ë¬´ìŒ íŒë‹¨ ìž„ê³„ê°’ (0.01~0.03)
const SILENCE_DURATION_MS = 5000; // 5ì´ˆ ë¬´ìŒ â†’ ìžë™ ì¢…ë£Œ
const STT_SOCKET_URL = 'wss://'; // ì‹¤ì œ STT ì„œë²„ ì£¼ì†Œë¡œ êµì²´

export const STREAM_STATUS = {
  IDLE: 'idle',
  PREPARING: 'preparing',
  RECORDING: 'recording',
  STOPPING: 'stopping',
  CLOSED: 'closed',
  ERROR: 'error',
};

/**
 * ðŸŽ™ useAudioStreaming
 * ì‹¤ì‹œê°„ ìŒì„± ìŠ¤íŠ¸ë¦¬ë° (STT) í›…
 * - ë‹µë³€ ë²„íŠ¼ í´ë¦­ â†’ WebSocket ì—°ê²° â†’ ìŒì„± ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡
 * - 5ì´ˆ ì´ìƒ ë¬´ìŒ â†’ ìžë™ ì¢…ë£Œ
 */
export default function useAudioStreaming() {
  const [status, setStatus] = useState(STREAM_STATUS.IDLE);
  const [isPaused, setIsPaused] = useState(false);
  const [rms, setRms] = useState(0);

  const socketRef = useRef(null);
  const mediaStreamRef = useRef(null);
  const audioContextRef = useRef(null);
  const workletRef = useRef(null);
  const vadIntervalRef = useRef(null);
  const lastVoiceTsRef = useRef(0);

  /** ðŸ”¹ ë…¹ìŒ ì¼ì‹œì •ì§€ */
  const pauseRecording = useCallback(() => {
    if (status === STREAM_STATUS.RECORDING && !isPaused) {
      console.log('[Audio] Pausing recording');
      setIsPaused(true);
    }
  }, [status, isPaused]);

  /** ðŸ”¹ ë…¹ìŒ ìž¬ê°œ */
  const resumeRecording = useCallback(() => {
    if (status === STREAM_STATUS.RECORDING && isPaused) {
      console.log('[Audio] Resuming recording');
      setIsPaused(false);
      lastVoiceTsRef.current = performance.now(); // ìž¬ê°œ ì‹œì ë¶€í„° ë¬´ìŒ ë‹¤ì‹œ ì²´í¬
    }
  }, [status, isPaused]);

  /** ðŸ”¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ */
  const cleanup = useCallback(() => {
    clearInterval(vadIntervalRef.current);

    try {
      workletRef.current?.port && (workletRef.current.port.onmessage = null);
      workletRef.current?.disconnect();
      mediaStreamRef.current?.getTracks().forEach((t) => t.stop());
      audioContextRef.current?.close();
      socketRef.current?.close(1000, 'client-cleanup');
    } catch (err) {
      console.warn('[Cleanup] error:', err);
    }

    setRms(0);
  }, []);

  /** ðŸ”¹ ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ */
  const stopRecording = useCallback(() => {
    if (status !== STREAM_STATUS.RECORDING) return;
    setStatus(STREAM_STATUS.STOPPING);

    try {
      socketRef.current?.send(JSON.stringify({type: 'stop'}));
    } catch (err) {
      console.warn('[STT] stop send failed:', err);
    }

    cleanup();
    setStatus(STREAM_STATUS.CLOSED);
  }, [status, cleanup]);

  /** ðŸ”¹ ë¬´ìŒ ê°ì§€ íƒ€ì´ë¨¸ */
  const startVadDetection = useCallback(() => {
    clearInterval(vadIntervalRef.current);
    vadIntervalRef.current = setInterval(() => {
      const silentFor = performance.now() - lastVoiceTsRef.current;
      if (silentFor >= SILENCE_DURATION_MS) {
        console.log(
          `[VAD] Silent for ${SILENCE_DURATION_MS / 1000}s â†’ auto stop`
        );
        stopRecording();
      }
    }, 250);
  }, [stopRecording]);

  // 0ï¸âƒ£ ì„œë²„ì—ì„œ STT WebSocket URLì„ ë°›ì•„ì˜¤ëŠ” í—¬í¼
  // âœ… 0) ì„œë²„ì—ì„œ STT WebSocket URLì„ ë°›ì•„ì˜¤ëŠ” í—¬í¼ (ì ˆëŒ€ URL ì‚¬ìš©)
  async function fetchSttSocketUrl() {
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), 7000);

    try {
      // ë°˜ë“œì‹œ í”„ë¡œí† ì½œ í¬í•¨!
      const API_BASE = 'http://52.91.161.156:8000';
      const endpoint = new URL(
        '/api/v1/interviews/prepare',
        API_BASE
      ).toString();

      const res = await fetch(endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Accept: 'application/json',
        },
        body: JSON.stringify({
          candidateId: '1',
          companyId: '1',
          personaInstanceIds: ['1', '2'],
        }),
        signal: controller.signal,
      });

      if (!res.ok)
        throw new Error(`Failed to fetch STT URL (HTTP ${res.status})`);

      const data = await res.json();
      if (!data?.websocketUrl) throw new Error('Response missing "url" field');

      return data.websocketUrl; // e.g. "ws://52.91.161.156:8000/ws/stt/xyz"
    } finally {
      clearTimeout(timeout);
    }
  }

  /** ðŸ”¹ ìŠ¤íŠ¸ë¦¬ë° ì‹œìž‘ */
  const startRecording = useCallback(async () => {
    if (
      status === STREAM_STATUS.RECORDING ||
      status === STREAM_STATUS.PREPARING
    )
      return;
    setStatus(STREAM_STATUS.PREPARING);

    try {
      // 1ï¸âƒ£ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
        video: false,
      });
      mediaStreamRef.current = stream;

      // 2ï¸âƒ£ AudioContext + Worklet ì„¤ì •
      const audioContext = new (window.AudioContext ||
        window.webkitAudioContext)({
        sampleRate: 16000,
      });
      await audioContext.audioWorklet.addModule('/pcmWorklet.js');
      const source = audioContext.createMediaStreamSource(stream);
      const worklet = new AudioWorkletNode(audioContext, 'pcm-writer');
      source.connect(worklet);

      audioContextRef.current = audioContext;
      workletRef.current = worklet;

      const Socket_Url = await fetchSttSocketUrl();
      if (!/^wss?:\/\//i.test(Socket_Url)) {
        throw new Error(`Invalid WS URL: ${Socket_Url}`);
      }

      // 3ï¸âƒ£ WebSocket ì—°ê²°
      const socket = new WebSocket(Socket_Url);
      socket.binaryType = 'arraybuffer';
      socketRef.current = socket;

      socket.onopen = () => {
        // STT ì‹œìž‘ ì‹ í˜¸
        socket.send(
          JSON.stringify({
            type: 'start',
            format: 'PCM16LE',
            sampleRate: 16000,
            lang: 'ko-KR',
          })
        );

        lastVoiceTsRef.current = performance.now();
        setStatus(STREAM_STATUS.RECORDING);
        startVadDetection();

        // 4ï¸âƒ£ Worklet â†’ WebSocketìœ¼ë¡œ ì „ì†¡
        worklet.port.onmessage = (e) => {
          const {type, rms: currentRms, payload} = e.data || {};
          if (type === 'level') {
            setRms(currentRms);
            if (currentRms > RMS_THRESHOLD) {
              lastVoiceTsRef.current = performance.now();
            }
          } else if (type === 'pcm') {
            if (
              socket.readyState === WebSocket.OPEN &&
              socket.bufferedAmount < 1_000_000
            ) {
              try {
                socket.send(payload);
              } catch {}
            }
          }
        };
      };

      socket.onerror = (err) => {
        console.error('[STT] Socket error:', err);
        setStatus(STREAM_STATUS.ERROR);
        cleanup();
      };

      socket.onclose = () => {
        cleanup();
        setStatus(STREAM_STATUS.CLOSED);
      };
    } catch (err) {
      console.error('[STT] startRecording failed:', err);
      setStatus(STREAM_STATUS.ERROR);
      cleanup();
    }
  }, [status, cleanup, startVadDetection]);

  /** ì–¸ë§ˆìš´íŠ¸ ì‹œ ìžë™ ì •ë¦¬ */
  useEffect(() => cleanup, [cleanup]);

  return {
    status,
    rms,
    startRecording,
    stopRecording,
    STATUS: STREAM_STATUS,
  };
}
