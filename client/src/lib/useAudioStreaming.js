// useAudioStreaming.js
import {useCallback, useEffect, useRef, useState} from 'react';

export const STREAM_STATUS = {
  IDLE: 'idle',
  PREPARING: 'preparing',
  RECORDING: 'recording',
  ERROR: 'error',
  CLOSED: 'closed',
};

// VADìš© ìž„ê³„ê°’ (RMS)
const VAD_THRESHOLD = 0.01;
// ë¬´ìŒ í—ˆìš© ì‹œê°„(ms)
const SILENCE_TIMEOUT = 4000;

export default function useAudioStreaming({getSocket, turnState} = {}) {
  const [status, setStatus] = useState(STREAM_STATUS.IDLE);
  const [rms, setRms] = useState(0);

  const audioContextRef = useRef(null);
  const mediaStreamRef = useRef(null);
  const workletRef = useRef(null);

  const lastVoiceTsRef = useRef(0);
  const hasSentAutoEndRef = useRef(false); // ìžë™ answer_end ì¤‘ë³µ ë°©ì§€

  /** ===========================
   *  ë…¹ìŒ ì‹œìž‘
   *  =========================== */
  const startRecording = useCallback(async () => {
    if (!getSocket) {
      console.warn('startRecording() called without getSocket');
      return;
    }

    const socket = getSocket();
    if (!socket || socket.readyState !== WebSocket.OPEN) {
      console.warn('socket not ready, skip recording');
      return;
    }

    if (
      status === STREAM_STATUS.PREPARING ||
      status === STREAM_STATUS.RECORDING
    ) {
      // ì´ë¯¸ ë…¹ìŒ ì¤‘ì´ê±°ë‚˜ ì¤€ë¹„ ì¤‘ì´ë©´ ë¬´ì‹œ
      return;
    }

    setStatus(STREAM_STATUS.PREPARING);

    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
        },
        video: false,
      });

      mediaStreamRef.current = stream;

      const AudioCtx = window.AudioContext || window.webkitAudioContext;
      const ctx = new AudioCtx({
        sampleRate: 16000,
      });

      await ctx.audioWorklet.addModule('/pcmWorklet.js');

      const source = ctx.createMediaStreamSource(stream);
      const worklet = new AudioWorkletNode(ctx, 'pcm-writer');

      source.connect(worklet);

      audioContextRef.current = ctx;
      workletRef.current = worklet;

      // VAD ì´ˆê¸°í™”
      const now = performance.now();
      lastVoiceTsRef.current = now;
      hasSentAutoEndRef.current = false;

      worklet.port.onmessage = (e) => {
        const data = e.data;
        if (!data || typeof data !== 'object') return;

        const {type, payload, rms: newRms} = data;

        // ðŸ”¹ ë ˆë²¨/VADìš© ë©”ì‹œì§€
        if (type === 'level') {
          if (typeof newRms === 'number') {
            setRms(newRms);
            if (newRms > VAD_THRESHOLD) {
              // ì†Œë¦¬ê°€ ë‚˜ë©´ ë§ˆì§€ë§‰ ë°œì„± ì‹œì  ê°±ì‹ 
              lastVoiceTsRef.current = performance.now();
              hasSentAutoEndRef.current = false; // ë‹¤ì‹œ ë§í•˜ë©´ autoEnd ê°€ëŠ¥ ìƒíƒœë¡œ
            }
          }
          return;
        }

        // ðŸ”¹ PCM ì „ì†¡
        if (type === 'pcm' && payload) {
          if (socket.readyState === WebSocket.OPEN) {
            try {
              socket.send(payload);
            } catch (err) {
              console.error('socket send failed:', err);
            }
          }
          return;
        }
      };

      setStatus(STREAM_STATUS.RECORDING);
    } catch (err) {
      console.error('startRecording failed:', err);
      setStatus(STREAM_STATUS.ERROR);
    }
  }, [getSocket, status]);

  /** ===========================
   *  ë…¹ìŒ ì¢…ë£Œ
   *  =========================== */
  const stopRecording = useCallback(() => {
    try {
      if (audioContextRef.current) {
        audioContextRef.current.close().catch(() => {});
      }
    } catch (_) {}

    audioContextRef.current = null;

    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((t) => t.stop());
    }
    mediaStreamRef.current = null;
    workletRef.current = null;

    setStatus(STREAM_STATUS.IDLE);
    setRms(0);
    hasSentAutoEndRef.current = false;
  }, []);

  /** ===========================
   *  ë¬´ìŒ(VAD) ê°ì§€ Polling
   *  =========================== */
  useEffect(() => {
    if (status !== STREAM_STATUS.RECORDING) return;
    if (!getSocket) return;

    const id = setInterval(() => {
      const socket = getSocket();
      if (!socket || socket.readyState !== WebSocket.OPEN) return;

      // ë‹µë³€ ì¤‘(ANSWERING)ì¼ ë•Œë§Œ VAD ì ìš©
      if (turnState !== 'answering') return;

      const now = performance.now();
      const diff = now - lastVoiceTsRef.current;

      // ì¼ì • ì‹œê°„ ì´ìƒ ë¬´ìŒ + ì•„ì§ autoEnd ì•ˆ ë³´ëƒˆìœ¼ë©´
      if (diff > SILENCE_TIMEOUT && !hasSentAutoEndRef.current) {
        console.log(
          '[VAD] silence detected, sending answer_end (diff:',
          diff,
          ')'
        );
        try {
          socket.send(JSON.stringify({type: 'answer_end'}));
          hasSentAutoEndRef.current = true;
        } catch (err) {
          console.error('failed to send answer_end:', err);
        }
      }
    }, 300);

    return () => clearInterval(id);
  }, [status, getSocket, turnState]);

  return {
    status,
    rms,
    startRecording,
    stopRecording,
    STATUS: STREAM_STATUS,
  };
}
