"""
Resume Verifier
10ê°œ Agentì˜ ëª¨ë“  Segment í‰ê°€ë¥¼ Resumeì™€ ë¹„êµ (AI 1íšŒ Batch)
"""

import json
from typing import Dict, List, Any
from openai import AsyncOpenAI


class ResumeVerifier:
    """
    Resume ê²€ì¦ê¸°
    
    ì—­í• :
        - 10ê°œ Agentì˜ ëª¨ë“  Segment í‰ê°€ë¥¼ Resumeì™€ ë¹„êµ
        - AI 1íšŒ í˜¸ì¶œë¡œ Batch ì²˜ë¦¬
        - ê° Segment í‰ê°€ì— Resume ê²€ì¦ ê²°ê³¼ ì¶”ê°€:
            * resume_verified: bool
            * verification_strength: "high"/"medium"/"low"/"none"
            * resume_evidence: List[str]
    """
    
    def __init__(self, openai_client: AsyncOpenAI):
        self.client = openai_client
    
    
    async def verify_batch(
        self,
        all_competency_results: Dict[str, Dict],
        resume_data: Dict
    ) -> List[Dict]:
        """
        Batch Resume ê²€ì¦
        
        Args:
            all_competency_results: 10ê°œ ì—­ëŸ‰ í‰ê°€ ê²°ê³¼
                {
                    "achievement_motivation": {...},
                    "growth_potential": {...},
                    ...
                }
            resume_data: íŒŒì‹±ëœ Resume JSON
                {
                    "education": [...],
                    "experience": [...],
                    "projects": [...],
                    "skills": [...]
                }
        
        Returns:
            segment_evaluations_with_resume: Resume ê²€ì¦ ì¶”ê°€ëœ Segment í‰ê°€ ëª©ë¡
                [
                    {
                        "competency": "achievement_motivation",
                        "segment_id": 3,
                        "score": 85,
                        "quotes": [...],
                        "interview_confidence": 0.85,
                        "resume_verified": true,
                        "verification_strength": "high",
                        "resume_evidence": ["í•™ë¶€ìƒ ì°½ì—… ê²½í—˜", ...]
                    },
                    ...
                ]
        """
        
        # 1. Segment í‰ê°€ ëª©ë¡ ì¶”ì¶œ
        segment_evaluations = self._extract_segment_evaluations(all_competency_results)
        
        print(f"\n[Resume Verifier] Segment í‰ê°€ ì¶”ì¶œ: {len(segment_evaluations)}ê°œ")
        
        # Resume ë°ì´í„° ì—†ìœ¼ë©´ ê²€ì¦ ìŠ¤í‚µ
        if not resume_data:
            print("  Resume ë°ì´í„° ì—†ìŒ - ê²€ì¦ ìŠ¤í‚µ")
            return self._add_empty_verification(segment_evaluations)
        
        
        # 2. AI í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_verification_prompt(segment_evaluations, resume_data)
        
        
        # 3. AI í˜¸ì¶œ (1íšŒ)
        print("[Resume Verifier] AI í˜¸ì¶œ ì‹œì‘ (Batch)...")
        
        response = await self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "You are a resume verification expert. Verify if interview segment evaluations are supported by the candidate's resume."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        result_text = response.choices[0].message.content
        print(f"[Resume Verifier] AI ì‘ë‹µ ê¸¸ì´: {len(result_text)} chars")
        
        
        # 4. ê²°ê³¼ íŒŒì‹±
        try:
            verification_results = json.loads(result_text)
            verified_list = verification_results.get("verifications", [])
            
            print(f"[Resume Verifier] ê²€ì¦ ì™„ë£Œ: {len(verified_list)}ê°œ")
            
            # ì›ë³¸ Segment í‰ê°€ì™€ ë³‘í•©
            merged = self._merge_verification_results(
                segment_evaluations,
                verified_list
            )
            
            return merged
        
        except json.JSONDecodeError as e:
            print(f"  JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._add_empty_verification(segment_evaluations)
    
    
    def _extract_segment_evaluations(
        self,
        all_competency_results: Dict[str, Dict]
    ) -> List[Dict]:
        """
        10ê°œ ì—­ëŸ‰ ê²°ê³¼ì—ì„œ Segment í‰ê°€ ì¶”ì¶œ
        
        Returns:
            [
                {
                    "competency": "achievement_motivation",
                    "segment_id": 3,
                    "score": 85,
                    "quotes": [...],
                    "interview_confidence": 0.85
                },
                ...
            ]
        """
        segment_evals = []
        
        for comp_name, comp_result in all_competency_results.items():
            if not comp_result:
                continue
            
            # Evidence detailsì—ì„œ Segment í‰ê°€ ì¶”ì¶œ
            perspectives = comp_result.get("perspectives", {})
            evidence_details = perspectives.get("evidence_details", [])
            overall_score = comp_result.get("overall_score", 0)
            overall_confidence = comp_result.get("confidence", {}).get("overall_confidence", 0.5)
            
            for detail in evidence_details:
                segment_eval = {
                    "competency": comp_name,
                    "segment_id": detail.get("segment_id"),
                    "quote_text": detail.get("text", ""),
                    "relevance_note": detail.get("relevance_note", ""),
                    "quality_score": detail.get("quality_score", 0.0),
                    "overall_score": overall_score,
                    "score": overall_score,
                    "interview_confidence": overall_confidence 
                }
                segment_evals.append(segment_eval)
        
        return segment_evals
    
    
    def _build_verification_prompt(
        self,
        segment_evaluations: List[Dict],
        resume_data: Dict
    ) -> str:
        """
        AI ê²€ì¦ í”„ë¡¬í”„íŠ¸ ìƒì„±
        """
        prompt = f"""# Task: Resume Verification (Batch) with Detailed Reasoning

    ë‹¹ì‹ ì€ ë©´ì ‘ ë‹µë³€ì´ Resume ê²½ë ¥ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    ## ì—­í• :
    1. ë©´ì ‘ì—ì„œ ì§€ì›ìê°€ ì–¸ê¸‰í•œ ê²½í—˜/ìŠ¤í‚¬ì´ Resumeì— ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸
    2. Resumeì˜ ì–´ëŠ ë¶€ë¶„(education, experience, projects ë“±)ê³¼ ë§¤ì¹­ë˜ëŠ”ì§€ **êµ¬ì²´ì ìœ¼ë¡œ** ëª…ì‹œ
    3. ê²€ì¦ ì‹ ë¢°ë„(high/medium/low/none)ë¥¼ íŒë‹¨í•˜ê³  **ê·¸ ê·¼ê±°ë¥¼ ìƒì„¸íˆ** ì œì‹œ

    ## Resume Data:
    ```json
    {json.dumps(resume_data, ensure_ascii=False, indent=2)}
    ```

    ## Segment Evaluations to Verify:
    ```json
    {json.dumps(segment_evaluations, ensure_ascii=False, indent=2)}
    ```

    ## ê²€ì¦ ê¸°ì¤€:

    **high (ê°•í•œ ê²€ì¦):**
    - Resumeì— êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œë¨ (í”„ë¡œì íŠ¸ëª…, ì—­í• , ê¸°ìˆ  ë“±)
    - ì—¬ëŸ¬ ì„¹ì…˜ì—ì„œ ì¼ê´€ë˜ê²Œ í™•ì¸ë¨
    - ì‹œê°„ì ìœ¼ë¡œ ëª¨ìˆœ ì—†ìŒ

    **medium (ì¤‘ê°„ ê²€ì¦):**
    - Resumeì— ê°„ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰ë¨ (ê´€ë ¨ ê²½í—˜ì€ ìˆìœ¼ë‚˜ êµ¬ì²´ì  ë‚´ìš© ë‹¤ë¦„)
    - ì¼ë¶€ ì„¹ì…˜ì—ì„œë§Œ í™•ì¸ë¨
    - ì‹œê°„ì ìœ¼ë¡œ ì•½ê°„ì˜ ë¶ˆì¼ì¹˜

    **low (ì•½í•œ ê²€ì¦):**
    - Resumeì— ë§¤ìš° ê°„ì ‘ì ìœ¼ë¡œë§Œ ì–¸ê¸‰ë¨
    - ì¶”ë¡  ê°€ëŠ¥í•˜ì§€ë§Œ ì§ì ‘ ì–¸ê¸‰ ì—†ìŒ

    **none (ê²€ì¦ ì‹¤íŒ¨):**
    - Resumeì— ì „í˜€ ê´€ë ¨ ë‚´ìš© ì—†ìŒ
    - ì‹œê°„ì ìœ¼ë¡œ ëª…ë°±í•œ ëª¨ìˆœ

    ## ì¶œë ¥ í˜•ì‹ (JSON):
    {{
    "verifications": [
        {{
        "competency": "achievement_motivation",
        "segment_id": 3,
        "quote_text": "í•™ë¶€ìƒ ë•Œ ì°½ì—… í”„ë¡œì íŠ¸ë¥¼ ì´ëŒì—ˆìŠµë‹ˆë‹¤",
        
        "resume_verified": true,
        "verification_strength": "high",
        
        "reasoning": "ì§€ì›ìëŠ” Resumeì˜ 'projects' ì„¹ì…˜ì— 'í•™ë¶€ìƒ ì°½ì—… í”„ë¡œì íŠ¸ (2020.03-2021.02, íŒ€ì¥)'ê°€ ëª…ì‹œë˜ì–´ ìˆìŒ. ê¸°ê°„, ì—­í• , í”„ë¡œì íŠ¸ëª…ì´ ëª¨ë‘ ì¼ì¹˜í•˜ë¯€ë¡œ ê²€ì¦ ê°•ë„ high. ë˜í•œ 'awards' ì„¹ì…˜ì— 'ëŒ€í•™ìƒ ì°½ì—… ê³µëª¨ì „ ëŒ€ìƒ (2021.11)'ì´ ìˆì–´ í”„ë¡œì íŠ¸ ì„±ê³¼ë„ í™•ì¸ë¨.",
        
        "resume_matches": [
            {{
            "resume_section": "projects",
            "matched_content": "í•™ë¶€ìƒ ì°½ì—… í”„ë¡œì íŠ¸ (2020.03-2021.02) | íŒ€ì¥ | íŒ¨ì…˜ íë ˆì´ì…˜ í”Œë«í¼ ê°œë°œ ë° ìš´ì˜",
            "relevance": "ë©´ì ‘ ë‹µë³€ì˜ 'ì°½ì—… í”„ë¡œì íŠ¸ ì´ëŒì—ˆë‹¤'ì™€ ì§ì ‘ ë§¤ì¹­. ì—­í• (íŒ€ì¥)ë„ ì¼ì¹˜."
            }},
            {{
            "resume_section": "awards",
            "matched_content": "ëŒ€í•™ìƒ ì°½ì—… ê³µëª¨ì „ ëŒ€ìƒ (2021.11, ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€)",
            "relevance": "í”„ë¡œì íŠ¸ì˜ ì„±ê³¼ë¥¼ ì…ì¦. ì‹œê°„ì ìœ¼ë¡œë„ í”„ë¡œì íŠ¸ ì¢…ë£Œ ì‹œì ê³¼ ì¼ì¹˜."
            }}
        ],
        
        "confidence_factors": {{
            "direct_evidence": true,
            "multiple_sources": true,
            "time_consistency": true,
            "detail_level": "high"
        }}
        }},
        {{
        "competency": "problem_solving",
        "segment_id": 1,
        "quote_text": "ë¬¸ì œë¥¼ ìˆ˜ìš”, ê³µê¸‰, ê°€ê²© ì„¸ ì¶•ìœ¼ë¡œ ë‚˜ëˆ ì„œ ë¶„ì„í•˜ëŠ” MECE ë°©ì‹ì„ ì„ í˜¸í•©ë‹ˆë‹¤",
        
        "resume_verified": true,
        "verification_strength": "medium",
        
        "reasoning": "ì§€ì›ìëŠ” Resumeì˜ 'education' ì„¹ì…˜ì— 'ê²½ì˜í•™ ì „ê³µ'ì´ ìˆìœ¼ë©°, MECEëŠ” ê²½ì˜í•™ í•„ìˆ˜ í”„ë ˆì„ì›Œí¬ì„. ê·¸ëŸ¬ë‚˜ Resumeì— MECEë¥¼ ì§ì ‘ ì–¸ê¸‰í•œ í”„ë¡œì íŠ¸ëŠ” ì—†ìŒ. 'projects'ì˜ 'ë¦¬í…Œì¼ ë°ì´í„° ë¶„ì„ ê³µëª¨ì „'ì—ì„œ 'ì‹œì¥ ì„¸ë¶„í™”' ê²½í—˜ì´ ìˆì–´ ê°„ì ‘ì ìœ¼ë¡œ êµ¬ì¡°ì  ë¶„ì„ ëŠ¥ë ¥ ì¶”ì • ê°€ëŠ¥. ì§ì ‘ ì¦ê±°ëŠ” ì•„ë‹ˆë¯€ë¡œ medium.",
        
        "resume_matches": [
            {{
            "resume_section": "education",
            "matched_content": "ì„œìš¸ëŒ€í•™êµ ê²½ì˜í•™ ì „ê³µ (2018.03-2022.02)",
            "relevance": "ê²½ì˜í•™ ì»¤ë¦¬í˜ëŸ¼ì— MECE, Issue Tree ë“± êµ¬ì¡°ì  ë¶„ì„ í”„ë ˆì„ì›Œí¬ í¬í•¨ë¨. ê°„ì ‘ ì¦ê±°."
            }},
            {{
            "resume_section": "projects",
            "matched_content": "ë¦¬í…Œì¼ ë°ì´í„° ë¶„ì„ ê³µëª¨ì „ (2021.09-2021.11) | ë°ì´í„° ë¶„ì„ ë‹´ë‹¹",
            "relevance": "ë°ì´í„° ë¶„ì„ ì‹œ êµ¬ì¡°ì  ì ‘ê·¼ì´ í•„ìš”í•˜ë‚˜, MECE ì§ì ‘ ì–¸ê¸‰ ì—†ìŒ."
            }}
        ],
        
        "confidence_factors": {{
            "direct_evidence": false,
            "multiple_sources": true,
            "time_consistency": true,
            "detail_level": "medium"
        }}
        }}
    ]
    }}

    ## ì¤‘ìš” ì§€ì¹¨:
    1. **reasoningì€ ë°˜ë“œì‹œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±**
    - Resumeì˜ ì–´ëŠ ì„¹ì…˜, ì–´ë–¤ ë‚´ìš©ê³¼ ë§¤ì¹­ë˜ëŠ”ì§€ ëª…ì‹œ
    - ì™œ ê·¸ verification_strengthì¸ì§€ ë…¼ë¦¬ì  ê·¼ê±° ì œì‹œ
    - ì‹œê°„ì  ì¼ê´€ì„±, ì—­í•  ì¼ì¹˜ ì—¬ë¶€ ë“± ì–¸ê¸‰

    2. **resume_matchesëŠ” 1ê°œ ì´ìƒ í•„ìˆ˜**
    - ì—¬ëŸ¬ ì„¹ì…˜ì—ì„œ í™•ì¸ë˜ë©´ ëª¨ë‘ ë‚˜ì—´
    - matched_contentëŠ” Resume ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¸ìš©
    - relevanceëŠ” ë©´ì ‘ ë‹µë³€ê³¼ì˜ ê´€ë ¨ì„± ì„¤ëª…

    3. **confidence_factorsë¡œ ê²€ì¦ ì‹ ë¢°ë„ ê·¼ê±° ëª…ì‹œ**
    - direct_evidence: Resumeì— ì§ì ‘ ì–¸ê¸‰ ì—¬ë¶€
    - multiple_sources: ì—¬ëŸ¬ ì„¹ì…˜ì—ì„œ í™•ì¸ ì—¬ë¶€
    - time_consistency: ì‹œê°„ì  ëª¨ìˆœ ì—†ìŒ
    - detail_level: Resume ê¸°ìˆ ì˜ êµ¬ì²´ì„± ìˆ˜ì¤€

    4. **Output ONLY valid JSON**
    - NO markdown code blocks
    - NO explanations outside JSON
    - ALL text in Korean

    """
        return prompt
    
    
    def _merge_verification_results(
        self,
        original_segments: List[Dict],
        verified_list: List[Dict]
    ) -> List[Dict]:
        """
        ì›ë³¸ Segment í‰ê°€ + Resume ê²€ì¦ ê²°ê³¼ ë³‘í•©
        """
        # Verification ê²°ê³¼ë¥¼ dictë¡œ ë³€í™˜ (ë¹ ë¥¸ ì¡°íšŒ)
        verification_map = {}
        for v in verified_list:
            key = (v.get("competency"), v.get("segment_id"))
            verification_map[key] = v
        
        # ë³‘í•©
        merged = []
        for seg in original_segments:
            key = (seg.get("competency"), seg.get("segment_id"))
            verification = verification_map.get(key, {})

            # âœ… ê¸°ë³¸ ê²€ì¦ í”Œë˜ê·¸/ê°•ë„ ê²°ì • (ë¹ˆ ë§¤ì¹­ì´ë©´ ê²€ì¦ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬)
            resume_matches = verification.get("resume_matches", [])
            resume_verified = bool(verification.get("resume_verified", False)) and bool(resume_matches)
            verification_strength = verification.get("verification_strength", "none") if resume_verified else "none"
            
            merged_seg = {
                **seg,
                
                "resume_verification": {
                    "verified": resume_verified,
                    "strength": verification_strength,
                    "reasoning": verification.get("reasoning", ""),  # ğŸ†•
                    "resume_matches": resume_matches,  # ğŸ†•
                    "confidence_factors": verification.get("confidence_factors", {})  # ğŸ†•
                }
            }
            merged.append(merged_seg)
        
        return merged
    
    
    def _add_empty_verification(
        self,
        segment_evaluations: List[Dict]
    ) -> List[Dict]:
        """
        Resume ê²€ì¦ ì—†ì´ ë¹ˆ í•„ë“œ ì¶”ê°€
        """
        return [
            {
                **seg,
                "resume_verification": { 
                    "verified": False,
                    "strength": "none",
                    "reasoning": "Resume ë°ì´í„° ì—†ìŒ",
                    "resume_matches": [],
                    "confidence_factors": {
                        "direct_evidence": False,
                        "multiple_sources": False,
                        "time_consistency": False,
                        "detail_level": "none"
                    }
                }
            }
            for seg in segment_evaluations
        ]
