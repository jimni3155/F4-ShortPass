# server/ai/parsers/persona_question_parser.py
"""
í˜ë¥´ì†Œë‚˜ ì§ˆë¬¸ PDF íŒŒì‹±
ê¸°ì—… ê´€ê³„ìë“¤ì´ ë‹µí•´ì•¼ í•  í•„ìˆ˜ ì§ˆë¬¸ë“¤ì„ PDFì—ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""
import pdfplumber
import io
import json
import boto3
from typing import List, Dict, Any, Optional
import re
from core.config import AWS_REGION, BEDROCK_MODEL_ID


class PersonaQuestionParser:
    """
    í˜ë¥´ì†Œë‚˜ ì§ˆë¬¸ PDF íŒŒì„œ

    PDFì—ì„œ ë©´ì ‘ ì§ˆë¬¸ë“¤ì„ ì¶”ì¶œí•˜ê³ , LLMì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì§ˆë¬¸ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        self.bedrock_runtime = boto3.client('bedrock-runtime', region_name=AWS_REGION)
        self.model_id = BEDROCK_MODEL_ID

    def parse_pdf(self, pdf_content: bytes) -> str:
        """
        PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

        Args:
            pdf_content: PDF íŒŒì¼ ë°”ì´ë„ˆë¦¬ ë‚´ìš©

        Returns:
            str: ì¶”ì¶œëœ ì „ì²´ í…ìŠ¤íŠ¸

        Raises:
            Exception: PDF íŒŒì‹± ì‹¤íŒ¨ ì‹œ
        """
        try:
            full_text = []

            with pdfplumber.open(io.BytesIO(pdf_content)) as pdf:
                print(f"ğŸ“„ PDF ë¡œë“œ: {len(pdf.pages)} í˜ì´ì§€")

                for page_num, page in enumerate(pdf.pages, 1):
                    text = page.extract_text()

                    if text:
                        cleaned_text = self._clean_text(text)
                        full_text.append(cleaned_text)
                        print(f"  í˜ì´ì§€ {page_num}: {len(cleaned_text)} ë¬¸ì")

            result = "\n\n".join(full_text)
            print(f"âœ“ ì´ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {len(result)} ë¬¸ì")

            return result

        except Exception as e:
            print(f"âŒ PDF íŒŒì‹± ì‹¤íŒ¨: {e}")
            raise Exception(f"Failed to parse PDF: {str(e)}")

    def _clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        # ì¤‘ë³µ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        return text

    def extract_questions_with_llm(self, pdf_text: str, company_name: str) -> Dict[str, Any]:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ PDF í…ìŠ¤íŠ¸ì—ì„œ êµ¬ì¡°í™”ëœ ì§ˆë¬¸ ë°ì´í„° ì¶”ì¶œ

        Args:
            pdf_text: PDFì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸
            company_name: íšŒì‚¬ëª…

        Returns:
            Dict containing:
                - questions: List[Dict] - ì¶”ì¶œëœ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
                - persona_info: Dict - í˜ë¥´ì†Œë‚˜ ë©”íƒ€ë°ì´í„°
        """
        prompt = f"""
ë‹¤ìŒì€ {company_name}ì˜ ë©´ì ‘ê´€ í˜ë¥´ì†Œë‚˜ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ PDF ë¬¸ì„œì…ë‹ˆë‹¤.
ì´ ë¬¸ì„œì—ì„œ ë©´ì ‘ ì§ˆë¬¸ë“¤ê³¼ í˜ë¥´ì†Œë‚˜ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

[PDF í…ìŠ¤íŠ¸]:
{pdf_text}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

{{
  "persona_info": {{
    "persona_name": "ë©´ì ‘ê´€ ì´ë¦„ ë˜ëŠ” ì—­í•  (ì˜ˆ: 'ê¸°ìˆ  ë©´ì ‘ê´€', 'HR ë©´ì ‘ê´€')",
    "archetype": "analytical|supportive|stress_tester ì¤‘ í•˜ë‚˜ (ë¬¸ì„œì˜ í†¤ì— ë”°ë¼)",
    "description": "í˜ë¥´ì†Œë‚˜ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª… (1-2ë¬¸ì¥)",
    "focus_areas": ["ì§‘ì¤‘ ì˜ì—­1", "ì§‘ì¤‘ ì˜ì—­2"]
  }},
  "questions": [
    {{
      "question_text": "ì§ˆë¬¸ ë‚´ìš©",
      "question_type": "technical|behavioral|situational|cultural ì¤‘ í•˜ë‚˜",
      "expected_keywords": ["ê¸°ëŒ€ë˜ëŠ”", "í‚¤ì›Œë“œ", "ë¦¬ìŠ¤íŠ¸"],
      "evaluation_criteria": ["í‰ê°€ ê¸°ì¤€1", "í‰ê°€ ê¸°ì¤€2"],
      "difficulty_level": 1-5 ì‚¬ì´ì˜ ì •ìˆ˜
    }}
  ]
}}

ì¤‘ìš”ì‚¬í•­:
1. ì§ˆë¬¸ì€ ëª…í™•í•˜ê²Œ êµ¬ë¶„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
2. ì§ˆë¬¸ì´ ëª…ì‹œì ìœ¼ë¡œ ì—†ìœ¼ë©´ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”
3. question_typeì€ ì§ˆë¬¸ì˜ ì„±ê²©ì— ë”°ë¼ ë¶„ë¥˜í•˜ì„¸ìš”
4. expected_keywordsëŠ” ì¢‹ì€ ë‹µë³€ì— í¬í•¨ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” í‚¤ì›Œë“œì…ë‹ˆë‹¤
5. evaluation_criteriaëŠ” ë‹µë³€ì„ í‰ê°€í•  ê¸°ì¤€ì…ë‹ˆë‹¤
6. difficulty_levelì€ ì§ˆë¬¸ì˜ ë‚œì´ë„ì…ë‹ˆë‹¤ (1=ì‰¬ì›€, 5=ì–´ë ¤ì›€)
7. JSONë§Œ ì‘ë‹µí•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
"""

        try:
            body = json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 4096,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3  # êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•´ ë‚®ì€ temperature
            })

            print("ğŸ¤– LLMìœ¼ë¡œ ì§ˆë¬¸ ì¶”ì¶œ ì¤‘...")

            response = self.bedrock_runtime.invoke_model(
                modelId=self.model_id,
                body=body,
                contentType="application/json",
                accept="application/json"
            )

            response_body = json.loads(response['body'].read().decode('utf-8'))
            llm_output = response_body['content'][0]['text'].strip()

            # JSON ì¶”ì¶œ (LLMì´ ì¶”ê°€ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
            json_match = re.search(r'\{.*\}', llm_output, re.DOTALL)
            if json_match:
                llm_output = json_match.group(0)

            result = json.loads(llm_output)

            print(f"âœ“ {len(result.get('questions', []))}ê°œì˜ ì§ˆë¬¸ ì¶”ì¶œ ì™„ë£Œ")

            return result

        except json.JSONDecodeError as e:
            print(f"âŒ LLM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"LLM ì¶œë ¥: {llm_output}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return self._extract_questions_fallback(pdf_text, company_name)

        except Exception as e:
            print(f"âŒ LLM ì§ˆë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # Fallback: ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì¶”ì¶œ
            return self._extract_questions_fallback(pdf_text, company_name)

    def _extract_questions_fallback(self, pdf_text: str, company_name: str) -> Dict[str, Any]:
        """
        LLM ì‹¤íŒ¨ ì‹œ í´ë°±: ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì§ˆë¬¸ ì¶”ì¶œ
        """
        print("âš ï¸  Fallback: ê·œì¹™ ê¸°ë°˜ ì§ˆë¬¸ ì¶”ì¶œ")

        # ì§ˆë¬¸ íŒ¨í„´ ì°¾ê¸° (ìˆ«ì. ë˜ëŠ” Q: ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸)
        question_patterns = [
            r'^\d+\.\s+(.+?)(?=\n\d+\.|\Z)',  # 1. ì§ˆë¬¸í˜•íƒœ
            r'^Q\d*[:)]\s+(.+?)(?=\nQ\d*[:)]|\Z)',  # Q: ë˜ëŠ” Q1: í˜•íƒœ
            r'^\?\s+(.+?)(?=\n\?|\Z)',  # ? ë¡œ ì‹œì‘
        ]

        questions = []
        for pattern in question_patterns:
            matches = re.finditer(pattern, pdf_text, re.MULTILINE | re.DOTALL)
            for match in matches:
                question_text = match.group(1).strip()
                if len(question_text) > 10:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
                    questions.append({
                        "question_text": question_text,
                        "question_type": "general",
                        "expected_keywords": [],
                        "evaluation_criteria": ["ë‹µë³€ì˜ ëª…í™•ì„±", "ë…¼ë¦¬ì  êµ¬ì¡°"],
                        "difficulty_level": 3
                    })

        # ì§ˆë¬¸ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°, ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ì§ˆë¬¸ ì„¸íŠ¸ë¡œ ì²˜ë¦¬
        if not questions:
            questions.append({
                "question_text": f"{company_name}ì—ì„œ ìš”êµ¬í•˜ëŠ” ì—­ëŸ‰ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                "question_type": "general",
                "expected_keywords": [],
                "evaluation_criteria": ["ë‹µë³€ì˜ ëª…í™•ì„±", "ê²½í—˜ì˜ êµ¬ì²´ì„±"],
                "difficulty_level": 3
            })

        return {
            "persona_info": {
                "persona_name": f"{company_name} ë©´ì ‘ê´€",
                "archetype": "analytical",
                "description": f"{company_name}ì˜ ì±„ìš© ê¸°ì¤€ì„ í‰ê°€í•˜ëŠ” ë©´ì ‘ê´€",
                "focus_areas": ["ì—­ëŸ‰ í‰ê°€"]
            },
            "questions": questions
        }

    def parse_persona_questions(
        self,
        pdf_content: bytes,
        company_name: str
    ) -> Dict[str, Any]:
        """
        í˜ë¥´ì†Œë‚˜ ì§ˆë¬¸ PDFë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„° ë°˜í™˜

        Args:
            pdf_content: PDF íŒŒì¼ ë°”ì´ë„ˆë¦¬
            company_name: íšŒì‚¬ëª…

        Returns:
            Dict containing:
                - full_text: ì›ë³¸ í…ìŠ¤íŠ¸
                - persona_info: í˜ë¥´ì†Œë‚˜ ë©”íƒ€ë°ì´í„°
                - questions: ì¶”ì¶œëœ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        print(f"\n{'='*60}")
        print(f"í˜ë¥´ì†Œë‚˜ ì§ˆë¬¸ PDF íŒŒì‹± ì‹œì‘: {company_name}")
        print(f"{'='*60}\n")

        # 1. PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        full_text = self.parse_pdf(pdf_content)

        # 2. LLMìœ¼ë¡œ ì§ˆë¬¸ ì¶”ì¶œ
        extracted_data = self.extract_questions_with_llm(full_text, company_name)

        result = {
            "full_text": full_text,
            "persona_info": extracted_data.get("persona_info", {}),
            "questions": extracted_data.get("questions", [])
        }

        print(f"\n{'='*60}")
        print(f"âœ“ íŒŒì‹± ì™„ë£Œ")
        print(f"  - ì§ˆë¬¸ ìˆ˜: {len(result['questions'])}")
        print(f"  - í˜ë¥´ì†Œë‚˜: {result['persona_info'].get('persona_name', 'N/A')}")
        print(f"{'='*60}\n")

        return result
